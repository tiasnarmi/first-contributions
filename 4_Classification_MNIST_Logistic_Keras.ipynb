{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4. Classification_MNIST_Logistic_Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.14"
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiasnarmi/first-contributions/blob/master/4_Classification_MNIST_Logistic_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YZ2OEWlmTAe",
        "colab_type": "text"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnkBMr5fmTAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU9yLfP_mTAk",
        "colab_type": "text"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhlGqC1NmTAl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b5dce6bf-e9d7-4580-c932-1d3ecc9afc68"
      },
      "source": [
        "(trainX, trainY), (testX, testY) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmpwylHJmTAo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6f995b0-d042-4db1-dd89-1c40046bc9dd"
      },
      "source": [
        "print(testY[0:5])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 2 1 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wOCudKMmcxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (trainX[2]) # What is in the training, is it has same Y?\n",
        "print(trainY[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hTGD_PemTAq",
        "colab_type": "text"
      },
      "source": [
        "### Convert Output label to multiple values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAQfO8KtmTAr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bab28095-337c-4da6-816b-f51fd6e9f3e8"
      },
      "source": [
        "print(trainY.shape)\n",
        "print('First 5 examples are: ', trainY[0:2])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n",
            "('First 5 examples are: ', array([5, 0], dtype=uint8))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdECB_ztmTAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is one hot encoding, For each output, you need to classify them in to 10 possibilities or where it falls on. \n",
        "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
        "testY = tf.keras.utils.to_categorical(testY, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCjgKJHKmTAw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f990358d-ab05-444a-8749-1512d5288330"
      },
      "source": [
        "print(trainY.shape)\n",
        "print('First 5 examples now are: ', trainY[0:2])\n",
        "# It tagged 5 for one of the output. and 0 for other. to tag 5, it tagged 1 where it had 5 and rest all 0s. "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "('First 5 examples now are: ', array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJtO4z63mTAz",
        "colab_type": "text"
      },
      "source": [
        "# Build the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCgMFVt9mTA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "0a844729-c8b3-44e4-8f56-4377bf78fc62"
      },
      "source": [
        "#Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Reshape data from 2D to 1D -> 28x28 to 784 # we reshape because linear equation expects vectors\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "#Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "#Comile the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# Loss is Categorical_crossentropy as we have multiple possible outputs. If Just 1 then we mention binary. "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfZyaKsHmTA5",
        "colab_type": "text"
      },
      "source": [
        "### Execute the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RygADOX9mTA7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        },
        "outputId": "1cec07e4-c5f9-4621-9c1e-6d7eaddc05aa"
      },
      "source": [
        "model.fit(trainX, trainY, \n",
        "          validation_data=(testX, testY), \n",
        "          epochs=50,\n",
        "          batch_size=trainX.shape[0])\n",
        "# Acc is train accuracy : 14%, and val_acc is test accuracy : 15%. It keeps improving. \n",
        "# Out of 10000 examples, model is predicting\n",
        "# It trained and predicted as well\n",
        "# Model cares about Loss, not accuracy. GD will worry about training loss\n",
        "# When do you say, model is good? Compare with human performance. How good is doctor doing, or how good is model doing?\n",
        "# If you retrain, it will start from last least loss which was 69%"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 1s 11us/sample - loss: 0.7719 - acc: 0.7872 - val_loss: 0.7384 - val_acc: 0.7821\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 0.7685 - acc: 0.7883 - val_loss: 0.7347 - val_acc: 0.7835\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 0.7652 - acc: 0.7893 - val_loss: 0.7312 - val_acc: 0.7845\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.7619 - acc: 0.7903 - val_loss: 0.7276 - val_acc: 0.7856\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7587 - acc: 0.7912 - val_loss: 0.7242 - val_acc: 0.7867\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7555 - acc: 0.7921 - val_loss: 0.7208 - val_acc: 0.7885\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7524 - acc: 0.7931 - val_loss: 0.7176 - val_acc: 0.7899\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7493 - acc: 0.7940 - val_loss: 0.7143 - val_acc: 0.7904\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7463 - acc: 0.7948 - val_loss: 0.7111 - val_acc: 0.7915\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7433 - acc: 0.7956 - val_loss: 0.7080 - val_acc: 0.7930\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7404 - acc: 0.7964 - val_loss: 0.7050 - val_acc: 0.7948\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7375 - acc: 0.7974 - val_loss: 0.7020 - val_acc: 0.7957\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7346 - acc: 0.7980 - val_loss: 0.6991 - val_acc: 0.7967\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7318 - acc: 0.7988 - val_loss: 0.6962 - val_acc: 0.7977\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7291 - acc: 0.7996 - val_loss: 0.6934 - val_acc: 0.7987\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7263 - acc: 0.8007 - val_loss: 0.6906 - val_acc: 0.7997\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7236 - acc: 0.8014 - val_loss: 0.6879 - val_acc: 0.8002\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7210 - acc: 0.8023 - val_loss: 0.6852 - val_acc: 0.8015\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7184 - acc: 0.8031 - val_loss: 0.6826 - val_acc: 0.8027\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7158 - acc: 0.8040 - val_loss: 0.6800 - val_acc: 0.8033\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7132 - acc: 0.8048 - val_loss: 0.6774 - val_acc: 0.8043\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7107 - acc: 0.8053 - val_loss: 0.6749 - val_acc: 0.8054\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7083 - acc: 0.8059 - val_loss: 0.6725 - val_acc: 0.8066\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7058 - acc: 0.8067 - val_loss: 0.6701 - val_acc: 0.8076\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7034 - acc: 0.8071 - val_loss: 0.6677 - val_acc: 0.8079\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7010 - acc: 0.8079 - val_loss: 0.6654 - val_acc: 0.8092\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6987 - acc: 0.8087 - val_loss: 0.6631 - val_acc: 0.8101\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6964 - acc: 0.8094 - val_loss: 0.6608 - val_acc: 0.8108\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6941 - acc: 0.8101 - val_loss: 0.6586 - val_acc: 0.8118\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6918 - acc: 0.8107 - val_loss: 0.6564 - val_acc: 0.8127\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6896 - acc: 0.8113 - val_loss: 0.6543 - val_acc: 0.8132\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6874 - acc: 0.8120 - val_loss: 0.6522 - val_acc: 0.8143\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6853 - acc: 0.8128 - val_loss: 0.6501 - val_acc: 0.8148\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6831 - acc: 0.8133 - val_loss: 0.6481 - val_acc: 0.8153\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6810 - acc: 0.8138 - val_loss: 0.6461 - val_acc: 0.8156\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6789 - acc: 0.8143 - val_loss: 0.6441 - val_acc: 0.8164\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6769 - acc: 0.8148 - val_loss: 0.6421 - val_acc: 0.8170\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6748 - acc: 0.8155 - val_loss: 0.6402 - val_acc: 0.8176\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6728 - acc: 0.8162 - val_loss: 0.6383 - val_acc: 0.8181\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6708 - acc: 0.8167 - val_loss: 0.6364 - val_acc: 0.8189\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6689 - acc: 0.8173 - val_loss: 0.6346 - val_acc: 0.8194\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6669 - acc: 0.8178 - val_loss: 0.6328 - val_acc: 0.8200\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6650 - acc: 0.8184 - val_loss: 0.6310 - val_acc: 0.8209\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6631 - acc: 0.8189 - val_loss: 0.6292 - val_acc: 0.8213\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6612 - acc: 0.8196 - val_loss: 0.6275 - val_acc: 0.8223\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6594 - acc: 0.8201 - val_loss: 0.6258 - val_acc: 0.8229\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6576 - acc: 0.8205 - val_loss: 0.6241 - val_acc: 0.8230\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6557 - acc: 0.8209 - val_loss: 0.6225 - val_acc: 0.8239\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6540 - acc: 0.8216 - val_loss: 0.6208 - val_acc: 0.8248\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.6522 - acc: 0.8220 - val_loss: 0.6192 - val_acc: 0.8250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f976ca6a2d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNl06prwmTA-",
        "colab_type": "text"
      },
      "source": [
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4JWRjMimTA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('models/mnist_lc.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}